# Llama_Quant_Int4_Triton
A collection of high-performance Triton (CUDA) kernels for 4-bit weight quantization and fast inference of low-bit LLMs)
